{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import json\n",
    "import tokenize\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source code extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_comments(source_code):\n",
    "    comments = []\n",
    "    tokens = tokenize.tokenize(BytesIO(source_code.encode(\"utf-8\")).readline)\n",
    "    for toknum, tokval, _, _, _ in tokens:\n",
    "        if toknum == tokenize.COMMENT:\n",
    "            comments.append(tokval.strip(\"# \").strip())\n",
    "    return comments\n",
    "\n",
    "def extract_docstrings_and_defs(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        source = f.read()\n",
    "\n",
    "    tree = ast.parse(source)\n",
    "    results = []\n",
    "    module_docstring = ast.get_docstring(tree)\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n",
    "            name = node.name\n",
    "            docstring = ast.get_docstring(node)\n",
    "            node_type = \"function\" if isinstance(node, ast.FunctionDef) else \"class\"\n",
    "            source_lines = source.splitlines()\n",
    "            start_line = node.lineno - 1  # ast 行号从1开始，列表索引从0开始\n",
    "            end_line = node.end_lineno if hasattr(node, 'end_lineno') else start_line\n",
    "            source_code = '\\n'.join(source_lines[start_line:end_line])\n",
    "            results.append({\n",
    "                \"type\": node_type,\n",
    "                \"name\": name,\n",
    "                \"docstring\": docstring or \"\",\n",
    "                \"source_code\": source_code,\n",
    "                \"file_docstring\": module_docstring\n",
    "            })\n",
    "\n",
    "    comments = extract_comments(source)\n",
    "    return results, comments\n",
    "\n",
    "def generate_qa_from_entry(entry):\n",
    "    name = entry[\"name\"]\n",
    "    doc = entry[\"docstring\"]\n",
    "    if not doc:\n",
    "        return None\n",
    "\n",
    "    # question = f\"What does the {entry['type']} `{name}` do?\"\n",
    "    # answer = doc.strip()\n",
    "    source_code = entry.get(\"source_code\", \"\")\n",
    "    file_docstring = entry.get(\"file_docstring\", \"\")\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"docstring\": doc.strip(),\n",
    "        \"file_docstring\": file_docstring,\n",
    "        \"source\": \"source_code\",\n",
    "        \"type\": entry[\"type\"],\n",
    "        \"code\": source_code\n",
    "    }\n",
    "\n",
    "def process_directory(dir_path):\n",
    "    qa_pairs = []\n",
    "    for root, _, files in tqdm(os.walk(dir_path)):\n",
    "        for file in tqdm(files):\n",
    "            if file.endswith(\".py\"):\n",
    "                full_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    entries, comments = extract_docstrings_and_defs(full_path)\n",
    "                    for entry in entries:\n",
    "                        qa = generate_qa_from_entry(entry)\n",
    "                        if qa:\n",
    "                            qa[\"file\"] = full_path\n",
    "                            qa_pairs.append(qa)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to parse {full_path}: {e}\")\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home/cc/transformers/src/transformers\"\n",
    "qa_data = process_directory(directory)\n",
    "\n",
    "# 保存结果为 JSONL 文件\n",
    "with open(\"source_code_qa.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for qa in qa_data:\n",
    "        f.write(json.dumps(qa, indent=4, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Extracted {len(qa_data)} QA pairs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Git commit extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仓库路径：替换为你本地 transformers 的路径\n",
    "REPO_PATH = \"/home/cc/transformers\"\n",
    "repo = Repo(REPO_PATH)\n",
    "\n",
    "output = []\n",
    "\n",
    "# 遍历最近 N 个 commit（可调整）\n",
    "for commit in repo.iter_commits('main', max_count=100):\n",
    "    commit_data = {\n",
    "        \"commit_hash\": commit.hexsha,\n",
    "        \"author\": commit.author.name,\n",
    "        \"date\": commit.committed_datetime.isoformat(),\n",
    "        \"message\": commit.message.strip()\n",
    "    }\n",
    "\n",
    "    # 获取 diff 的简要变化（可设置为 full_diff=True 看更多上下文）\n",
    "    diffs = commit.diff(commit.parents[0] if commit.parents else None, create_patch=True)\n",
    "\n",
    "    diff_texts = []\n",
    "    for diff in diffs:\n",
    "        try:\n",
    "            diff_texts.append(diff.diff.decode(\"utf-8\", errors=\"ignore\"))\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    diff_summary = \"\\n\".join(diff_texts)\n",
    "    commit_data[\"diff_summary\"] = diff_summary\n",
    "\n",
    "    # 构造 QA 对\n",
    "    # qa_item = {\n",
    "    #     \"question\": f\"What changed in commit {commit.hexsha[:7]}?\",\n",
    "    #     \"answer\": f\"{commit.message.strip()}\\n\\nSummary of changes:\\n{diff_summary[:1000]}...\",\n",
    "    #     \"source\": \"git_commit\",\n",
    "    #     \"metadata\": commit_data\n",
    "    # }\n",
    "    qa_item = {\n",
    "        \"question\": f\"What changed in commit {commit.hexsha[:7]}?\",\n",
    "        \"answer\": f\"{commit.message.strip()}\",\n",
    "        \"source\": \"git_commit\",\n",
    "        \"metadata\": commit_data\n",
    "    }\n",
    "\n",
    "    output.append(qa_item)\n",
    "\n",
    "# 保存为 JSONL\n",
    "with open(\"qa_from_commits.jsonl\", \"w\") as f:\n",
    "    for item in output:\n",
    "        f.write(json.dumps(item, indent=4, ensure_ascii=False) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformerQA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
