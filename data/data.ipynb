{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import json\n",
    "import tokenize\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source code extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_comments(source_code):\n",
    "    comments = []\n",
    "    tokens = tokenize.tokenize(BytesIO(source_code.encode(\"utf-8\")).readline)\n",
    "    for toknum, tokval, _, _, _ in tokens:\n",
    "        if toknum == tokenize.COMMENT:\n",
    "            comments.append(tokval.strip(\"# \").strip())\n",
    "    return comments\n",
    "\n",
    "def extract_docstrings_and_defs(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        source = f.read()\n",
    "\n",
    "    tree = ast.parse(source)\n",
    "    results = []\n",
    "    module_docstring = ast.get_docstring(tree)\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n",
    "            name = node.name\n",
    "            docstring = ast.get_docstring(node)\n",
    "            node_type = \"function\" if isinstance(node, ast.FunctionDef) else \"class\"\n",
    "            source_lines = source.splitlines()\n",
    "            start_line = node.lineno - 1  # ast 行号从1开始，列表索引从0开始\n",
    "            end_line = node.end_lineno if hasattr(node, 'end_lineno') else start_line\n",
    "            source_code = '\\n'.join(source_lines[start_line:end_line])\n",
    "            results.append({\n",
    "                \"type\": node_type,\n",
    "                \"name\": name,\n",
    "                \"docstring\": docstring or \"\",\n",
    "                \"source_code\": source_code,\n",
    "                \"file_docstring\": module_docstring\n",
    "            })\n",
    "\n",
    "    comments = extract_comments(source)\n",
    "    return results, comments\n",
    "\n",
    "def generate_qa_from_entry(entry):\n",
    "    name = entry[\"name\"]\n",
    "    doc = entry[\"docstring\"]\n",
    "    if not doc:\n",
    "        return None\n",
    "\n",
    "    # question = f\"What does the {entry['type']} `{name}` do?\"\n",
    "    # answer = doc.strip()\n",
    "    source_code = entry.get(\"source_code\", \"\")\n",
    "    file_docstring = entry.get(\"file_docstring\", \"\")\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"docstring\": doc.strip(),\n",
    "        \"file_docstring\": file_docstring,\n",
    "        \"source\": \"source_code\",\n",
    "        \"type\": entry[\"type\"],\n",
    "        \"code\": source_code\n",
    "    }\n",
    "\n",
    "def process_directory(dir_path):\n",
    "    qa_pairs = []\n",
    "    for root, _, files in tqdm(os.walk(dir_path)):\n",
    "        for file in tqdm(files):\n",
    "            if file.endswith(\".py\"):\n",
    "                full_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    entries, comments = extract_docstrings_and_defs(full_path)\n",
    "                    for entry in entries:\n",
    "                        qa = generate_qa_from_entry(entry)\n",
    "                        if qa:\n",
    "                            qa[\"file\"] = full_path\n",
    "                            qa_pairs.append(qa)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to parse {full_path}: {e}\")\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:02<00:00, 25.14it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 117.14it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 93.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1956.30it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 19222.29it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 46776.62it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 99.02it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 66974.91it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 27413.75it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22733.36it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 49636.73it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 92.11it/s]\n",
      "100%|██████████| 36/36 [00:00<00:00, 67.93it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 89.41it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 76.03it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 101.47it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 19.61it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 338.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 116.90it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 60.39it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 27.76it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 43.38it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 33.64it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 81.73it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 43.78it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 85.50it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 55.56it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 68.52it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 29.33it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 46.03it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 26.51it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 72.89it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 75.98it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 338.63it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 34.62it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 186.04it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 56.72it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 19.51it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 109.53it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 54.30it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 61.92it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 70.71it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 25.79it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 84.67it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 65.89it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 267.80it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 92.55it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 70.89it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 170.04it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 129.13it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 107.98it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 31.29it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 38.66it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 43.40it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 82.62it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 44.31it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 30.75it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 45.47it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 32.03it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 39.47it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 144.02it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 61.56it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 77.59it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 43.14it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 23.33it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 55.43it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 70.95it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 210.63it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 43.64it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 84.72it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 189.42it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 66.99it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 78.88it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 55.93it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 86.79it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 124.53it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 85.29it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 98.56it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 45.23it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 60.80it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 37.74it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 93.87it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 52.61it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 137.52it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 161.29it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 47.27it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 179.90it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 29.66it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 57.45it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 24.03it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 46.26it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 26.18it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 102.00it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 71.45it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 196.15it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 107.70it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 44.61it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 26.41it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 91.99it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 48.17it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 42.84it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 77.46it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 44.40it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 72.35it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 59.93it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 82.02it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 67.07it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 37.59it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 65.18it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 61.97it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 115.09it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 173.85it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 38.47it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 32.75it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 52.73it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 40.46it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 39.56it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 73.51it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 17.53it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 67.62it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 43.60it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 101.52it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 76.75it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 45.77it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 92.29it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 34.11it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 95.15it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 57.16it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 950.98it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 46.42it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 37.74it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 38.93it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 75.79it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 67.31it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 95.42it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 94.43it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 75.82it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 53.74it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 53.39it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 73.03it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 97.19it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 122.36it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 38.38it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 102.37it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 40.66it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 62.15it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.65it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 47.54it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 97.21it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 75.41it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 60.18it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 29.20it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 51.06it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 90.56it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 110.72it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 66.27it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 31.51it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 60.97it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 96.82it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 158.64it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 48.19it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 75.24it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 129.45it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 35.02it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 100.02it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 80.95it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 39.25it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 63.22it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 72.49it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 38.11it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 33.89it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.20it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 132.58it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 49.08it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 25.09it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 38.37it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 87.31it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 34.89it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 79.05it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 39.66it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 59.41it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 124.75it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 63.97it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 30.84it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 41.77it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 33.35it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 59.27it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 50.01it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 88.59it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 70.71it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 68.07it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 222.82it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 42.53it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 26.93it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 28.24it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 67.93it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 54.51it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 138.34it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 46.15it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 44.95it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 171.51it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 86.35it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 45.67it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 40.27it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 81.77it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 34.66it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 46.34it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 65.96it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 65.69it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 61.17it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 50.81it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 93.55it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 55.77it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 67.45it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 39.37it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 127.76it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 30.73it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 55.53it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 47.89it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 113.20it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 139.35it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 65.37it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 25.57it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 13.99it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 32.46it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 65.17it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 10.91it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 58.55it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 109.24it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 57.74it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 48.18it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 217.20it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 21.24it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 37.48it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 35.40it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 96.70it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 70.56it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 48.06it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 74.12it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 31.62it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 87.70it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 127.69it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 114.56it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 43.16it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 26.33it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 116.86it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 49.93it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 40.96it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 148.96it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 29.43it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 45.98it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 32.22it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 53.93it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 27.52it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 65.75it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 88.42it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 65.09it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 76.34it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 56.88it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 108.95it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 56.65it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 73.56it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 29.33it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 50.42it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 15.81it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 39.90it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 66.13it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 42.16it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 65.57it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 223.99it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 44.71it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 43.47it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 207.31it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 31.42it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 47.87it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 105.75it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 34.56it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 61.04it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 80.58it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 32.49it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 36.35it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 37.88it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 113.21it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 133.26it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 31.00it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 49.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 887.87it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 64.03it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 67.96it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 136.04it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 70.98it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 116.84it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 86.07it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 40.07it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 103.13it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 42.66it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 20.83it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 139.74it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 118.91it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 46.43it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 236.87it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 57.43it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 43.14it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 45.01it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 82.36it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 24.25it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 66.45it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 78.65it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 259.31it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 47.68it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 100.92it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 30.94it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 62.82it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 139.30it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 105.38it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 55.92it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 32.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 97.48it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 36.42it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 55.11it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 115.44it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 67.28it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 71.67it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 93.62it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 51.84it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 74.42it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 26.30it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 45.68it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 50.86it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 107.10it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 45.13it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 89.71it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 136.21it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 43.21it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 203.91it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 82.18it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 73.54it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 92.64it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 88.75it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 39.74it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 34.70it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 50.24it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 54.96it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 132.83it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 67.33it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 50.58it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 92.11it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 44.12it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 33.41it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 83.63it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 51.97it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 36.24it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 61.78it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 57.88it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 81.12it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 45.30it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 23.20it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 163.79it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 38.09it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 35.44it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 24.48it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22.11it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 138.26it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 77.65it/s]\n",
      "364it [00:44,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 12678 QA pairs.\n"
     ]
    }
   ],
   "source": [
    "directory = \"/home/cc/transformers/src/transformers\"\n",
    "qa_data = process_directory(directory)\n",
    "\n",
    "# 保存结果为 JSONL 文件\n",
    "with open(\"source_code_qa.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(qa_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Extracted {len(qa_data)} QA pairs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "api_key = input(\"Enter your openai api key: \")\n",
    "# api_base = input(\"Enter your openai api base: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "# os.environ[\"OPENAI_API_BASE\"] = api_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_docstring(name, type, docstring):\n",
    "    # 使用 GPT 模型生成摘要\n",
    "    prompt = \"\"\"\n",
    "    Summarize the following docstring, tell me what does the {type} `{name}` do.\n",
    "    Docstring:\n",
    "    {docstring}\n",
    "    \"\"\"\n",
    "    question_pool = [\n",
    "        \"What does the {type} {name} do?\"\n",
    "        \"What is the function of the {type} {name}?\",\n",
    "        \"How does the {type} {name} work?\",\n",
    "        \"What role does the {type} {name} play?\",\n",
    "        \"What is the purpose of the {type} {name}?\",\n",
    "        \"What does the {type} {name} accomplish?\",\n",
    "        \"Can you explain what the {type} {name} is used for?\",\n",
    "        \"Why do we need the {type} {name}?\",\n",
    "        \"What is the {type} {name} responsible for?\",\n",
    "        \"What task does the {type} {name} perform?\",\n",
    "        \"What kind of behavior does the {type} {name} define?\"\n",
    "    ]\n",
    "    question = random.choice(question_pool)\n",
    "    question = question.format(name=name, type=type)\n",
    "    client = OpenAI()\n",
    "    prompt = prompt.format(name=name, type=type, docstring=docstring)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    return question, response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `softmax_backward_data` function is designed to invoke the internal `_softmax_backward_data` method in PyTorch. Its main purpose is to handle and adjust the arguments it passes to this internal method based on the version of PyTorch that is being used.\n",
      "The `id_tensor_storage` function provides a unique identifier for a tensor's underlying storage. It ensures that multiple tensors sharing the same storage will have the same identifier. The identifier remains constant and unique for the storage's lifetime, although different storages with non-overlapping lifetimes might share the same identifier.\n",
      "The `Conv1D` class implements a 1D-convolutional layer used in models like OpenAI's GPT and GPT-2. It functions similarly to a linear layer but with transposed weights. The class takes two arguments: `nf`, the number of output features, and `nx`, the number of input features.\n",
      "The function `prune_layer` reduces a given Conv1D or linear layer by keeping only the specified indices, effectively pruning the layer. It is primarily used to remove heads. The function requires a layer and indices to keep as inputs and optionally the dimension to apply these indices. It returns a new pruned layer with gradients enabled.\n",
      "The `meshgrid` function serves as a wrapper for `torch.meshgrid` to prevent warning messages related to the newly introduced `indexing` argument. This suggests that the function is a slightly modified version of `torch.meshgrid`, likely retaining its primary functionality while managing changes in the argument structure to ensure compatibility and to suppress warnings.\n",
      "The function `apply_chunking_to_forward` takes input tensors and divides them into smaller chunks along a specified dimension, according to a provided chunk size. It then applies a given forward function, `forward_fn`, to each of these chunks independently. This process is intended to save memory. The function returns a tensor that should match the output of applying `forward_fn` directly to the entire `input_tensors`, assuming `forward_fn` operates independently across the specified dimension.\n",
      "The function `find_pruneable_heads_and_indices` identifies which heads in a model can be pruned, considering a set of heads that have already been pruned. It takes as input a list of heads to potentially prune, the total number of heads in the model, the size of each head, and a set of already pruned heads. The function returns a tuple that includes a set of the indices of heads that can be pruned and a tensor containing the indices of the rows and columns to keep in the layer's weight matrix.\n",
      "The function `prune_linear_layer` modifies a given linear layer by retaining only the entries specified in the provided index. It's primarily used for removing specific heads, likely in a multi-head attention context. The function accepts three arguments: the linear layer to be pruned, a tensor of indices representing the entries to keep, and an optional dimension parameter (defaulting to 0) that specifies the dimension along which the pruning should be applied. The function returns a new `torch.nn.Linear` layer with the pruning applied and gradient computation enabled.\n",
      "The `prune_conv1d_layer` function is designed to prune a `Conv1D` layer by retaining only specific entries specified by the `index`. It treats the `Conv1D` layer similarly to a linear layer but with transposed weights. This function is typically used for removing heads from models like BERT. It takes the layer to be pruned, the indices to retain, and an optional dimension parameter (defaulting to 1) as arguments. The function returns a new pruned `Conv1D` layer with `requires_grad` set to `True`.\n",
      "The function `isin_mps_friendly` is designed to perform the same operation as `torch.isin` without using any additional flags, but it is specifically tailored to work well with Apple's Metal Performance Shaders (MPS). This function checks whether each element in the input tensor `elements` is present within the `test_elements` tensor or integer. It returns a boolean tensor of the same shape as `elements`, with True where the element is found in `test_elements` and False otherwise. This function is intended as a temporary workaround for compatibility with versions of PyTorch up to 2.3, due to a relevant issue discussed in the PyTorch GitHub repository.\n"
     ]
    }
   ],
   "source": [
    "with open(\"source_code_qa.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    qa_data = json.load(f)\n",
    "\n",
    "qa_data_with_summary = []\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(summarize_docstring, qa[\"name\"], qa[\"type\"], qa[\"docstring\"]) for qa in qa_data[:10]]\n",
    "    for future in as_completed(futures):\n",
    "        qa = qa_data[futures.index(future)]\n",
    "        qa[\"question\"], qa[\"answer\"] = future.result()\n",
    "        qa_data_with_summary.append(qa)\n",
    "\n",
    "with open(\"source_code_qa_with_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(qa_data_with_summary, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Git commit extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仓库路径：替换为你本地 transformers 的路径\n",
    "REPO_PATH = \"/home/cc/transformers\"\n",
    "repo = Repo(REPO_PATH)\n",
    "\n",
    "output = []\n",
    "\n",
    "# 遍历最近 N 个 commit（可调整）\n",
    "for commit in repo.iter_commits('main', max_count=10000):\n",
    "    commit_data = {\n",
    "        \"commit_hash\": commit.hexsha,\n",
    "        \"author\": commit.author.name,\n",
    "        \"date\": commit.committed_datetime.isoformat(),\n",
    "        \"message\": commit.message.strip()\n",
    "    }\n",
    "\n",
    "    # 获取 diff 的简要变化（可设置为 full_diff=True 看更多上下文）\n",
    "    diffs = commit.diff(commit.parents[0] if commit.parents else None, create_patch=True)\n",
    "\n",
    "    diff_texts = []\n",
    "    for diff in diffs:\n",
    "        try:\n",
    "            diff_texts.append(diff.diff.decode(\"utf-8\", errors=\"ignore\"))\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    diff_summary = \"\\n\".join(diff_texts)\n",
    "    commit_data[\"diff_summary\"] = diff_summary\n",
    "\n",
    "    # 构造 QA 对\n",
    "    # qa_item = {\n",
    "    #     \"question\": f\"What changed in commit {commit.hexsha[:7]}?\",\n",
    "    #     \"answer\": f\"{commit.message.strip()}\\n\\nSummary of changes:\\n{diff_summary[:1000]}...\",\n",
    "    #     \"source\": \"git_commit\",\n",
    "    #     \"metadata\": commit_data\n",
    "    # }\n",
    "    question_pool = [\n",
    "        \"What changed in commit {hash}?\",\n",
    "        \"What modifications were introduced in commit {hash}?\",\n",
    "        \"Can you summarize the changes made in commit {hash}?\",\n",
    "        \"What updates does commit {hash} contain?\",\n",
    "        \"What's new in commit {hash}?\",\n",
    "        \"Describe the differences introduced by commit {hash}.\",\n",
    "        \"What was added, removed, or modified in commit {hash}?\",\n",
    "        \"What does commit {hash} change in the codebase?\",\n",
    "        \"Which files or functions were affected by commit {hash}?\",\n",
    "        \"What's the purpose of commit {hash}?\",\n",
    "        \"How does commit {hash} alter the existing implementation?\"\n",
    "    ]\n",
    "    question = random.choice(question_pool)\n",
    "    question = question.format(hash=commit.hexsha[:7])\n",
    "    qa_item = {\n",
    "        \"question\": question,\n",
    "        \"answer\": f\"{commit.message.strip()}\",\n",
    "        \"source\": \"git_commit\",\n",
    "        \"metadata\": commit_data\n",
    "    }\n",
    "\n",
    "    output.append(qa_item)\n",
    "\n",
    "    question_pool = [\n",
    "        \"Who is the author of the commit {hash}?\",\n",
    "        \"Who made the commit {hash}?\",\n",
    "        \"Who is responsible for commit {hash}?\",\n",
    "        \"Can you tell me who authored commit {hash}?\",\n",
    "        \"Who's the person behind commit {hash}?\",\n",
    "        \"Who committed {hash}?\",\n",
    "        \"Which developer authored commit {hash}?\",\n",
    "        \"Who was the contributor for commit {hash}?\",\n",
    "        \"Do you know who wrote commit {hash}?\",\n",
    "        \"Who pushed commit {hash} to the repository?\",\n",
    "        \"Whose work is represented by commit {hash}?\"\n",
    "    ]\n",
    "    question = random.choice(question_pool)\n",
    "    question = question.format(hash=commit.hexsha[:7])\n",
    "    qa_item = {\n",
    "        \"question\": question,\n",
    "        \"answer\": f\"{commit.author.name}\",\n",
    "        \"source\": \"git_commit\",\n",
    "        \"metadata\": commit_data\n",
    "    }\n",
    "    output.append(qa_item)\n",
    "\n",
    "    question_pool = [\n",
    "        \"When was the commit {hash} made?\",\n",
    "        \"What is the timestamp of commit {hash}?\",\n",
    "        \"When exactly did commit {hash} occur?\",\n",
    "        \"At what time was commit {hash} created?\",\n",
    "        \"Can you tell me the date of commit {hash}?\",\n",
    "        \"On what date was commit {hash} made?\",\n",
    "        \"Do you know when commit {hash} was pushed?\",\n",
    "        \"Any idea when commit {hash} happened?\",\n",
    "        \"When did commit {hash} go through?\",\n",
    "        \"What's the date on commit {hash}?\",\n",
    "        \"When did they make commit {hash}?\"\n",
    "    ]\n",
    "    question = random.choice(question_pool)\n",
    "    question = question.format(hash=commit.hexsha[:7])\n",
    "    qa_item = {\n",
    "        \"question\": question,\n",
    "        \"answer\": f\"{commit.committed_datetime.isoformat()}\",\n",
    "        \"source\": \"git_commit\",\n",
    "        \"metadata\": commit_data\n",
    "    }\n",
    "    output.append(qa_item)\n",
    "# 保存为 JSON\n",
    "with open(\"qa_from_commits.json\", \"w\") as f:\n",
    "    json.dump(output, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github issue extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github import Github\n",
    "g_token = input(\"Enter your github token: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Check fork\n",
      "Body: # What does this PR do?\n",
      "\n",
      "<!--\n",
      "Congratulations! You've made it this far! You're not quite done yet though.\n",
      "\n",
      "Once merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\n",
      "\n",
      "Then, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\n",
      "\n",
      "Once you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\n",
      "-->\n",
      "\n",
      "<!-- Remove if not applicable -->\n",
      "\n",
      "Fixes # (issue)\n",
      "\n",
      "\n",
      "## Before submitting\n",
      "- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\n",
      "- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\n",
      "      Pull Request section?\n",
      "- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\n",
      "      to it if that's the case.\n",
      "- [ ] Did you make sure to update the documentation with your changes? Here are the\n",
      "      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\n",
      "      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\n",
      "- [ ] Did you write any new necessary tests?\n",
      "\n",
      "\n",
      "## Who can review?\n",
      "\n",
      "Anyone in the community is free to review the PR once the tests have passed. Feel free to tag\n",
      "members/contributors who may be interested in your PR.\n",
      "\n",
      "<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\n",
      "\n",
      " If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\n",
      " Please tag fewer than 3 people.\n",
      "\n",
      "Models:\n",
      "\n",
      "- text models: @ArthurZucker\n",
      "- vision models: @amyeroberts, @qubvel\n",
      "- speech models: @eustlb\n",
      "- graph models: @clefourrier\n",
      "\n",
      "Library:\n",
      "\n",
      "- flax: @gante and @Rocketknight1\n",
      "- generate: @zucchini-nlp (visual-language models) or @gante (all others)\n",
      "- pipelines: @Rocketknight1\n",
      "- tensorflow: @gante and @Rocketknight1\n",
      "- tokenizers: @ArthurZucker\n",
      "- trainer: @zach-huggingface and @SunMarc\n",
      "- chat templates: @Rocketknight1\n",
      "\n",
      "Integrations:\n",
      "\n",
      "- deepspeed: HF Trainer/Accelerate: @SunMarc @zach-huggingface\n",
      "- ray/raytune: @richardliaw, @amogkam\n",
      "- Big Model Inference: @SunMarc\n",
      "- quantization (bitsandbytes, autogpt): @SunMarc @MekkCyber\n",
      "\n",
      "Documentation: @stevhliu\n",
      "\n",
      "HF projects:\n",
      "\n",
      "- accelerate: [different repo](https://github.com/huggingface/accelerate)\n",
      "- datasets: [different repo](https://github.com/huggingface/datasets)\n",
      "- diffusers: [different repo](https://github.com/huggingface/diffusers)\n",
      "- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\n",
      "\n",
      "Maintained examples (not research project or legacy):\n",
      "\n",
      "- Flax: @Rocketknight1\n",
      "- PyTorch: See Models above and tag the person corresponding to the modality of the example.\n",
      "- TensorFlow: @Rocketknight1\n",
      "\n",
      " -->\n",
      "\n",
      "Title: [do not merge] ci check\n",
      "Body: # What does this PR do?\n",
      "\n",
      "<!--\n",
      "Congratulations! You've made it this far! You're not quite done yet though.\n",
      "\n",
      "Once merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\n",
      "\n",
      "Then, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\n",
      "\n",
      "Once you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\n",
      "-->\n",
      "\n",
      "<!-- Remove if not applicable -->\n",
      "\n",
      "Fixes # (issue)\n",
      "\n",
      "\n",
      "## Before submitting\n",
      "- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\n",
      "- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\n",
      "      Pull Request section?\n",
      "- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\n",
      "      to it if that's the case.\n",
      "- [ ] Did you make sure to update the documentation with your changes? Here are the\n",
      "      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\n",
      "      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\n",
      "- [ ] Did you write any new necessary tests?\n",
      "\n",
      "\n",
      "## Who can review?\n",
      "\n",
      "Anyone in the community is free to review the PR once the tests have passed. Feel free to tag\n",
      "members/contributors who may be interested in your PR.\n",
      "\n",
      "<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\n",
      "\n",
      " If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\n",
      " Please tag fewer than 3 people.\n",
      "\n",
      "Models:\n",
      "\n",
      "- text models: @ArthurZucker\n",
      "- vision models: @amyeroberts, @qubvel\n",
      "- speech models: @eustlb\n",
      "- graph models: @clefourrier\n",
      "\n",
      "Library:\n",
      "\n",
      "- flax: @gante and @Rocketknight1\n",
      "- generate: @zucchini-nlp (visual-language models) or @gante (all others)\n",
      "- pipelines: @Rocketknight1\n",
      "- tensorflow: @gante and @Rocketknight1\n",
      "- tokenizers: @ArthurZucker\n",
      "- trainer: @zach-huggingface and @SunMarc\n",
      "- chat templates: @Rocketknight1\n",
      "\n",
      "Integrations:\n",
      "\n",
      "- deepspeed: HF Trainer/Accelerate: @SunMarc @zach-huggingface\n",
      "- ray/raytune: @richardliaw, @amogkam\n",
      "- Big Model Inference: @SunMarc\n",
      "- quantization (bitsandbytes, autogpt): @SunMarc @MekkCyber\n",
      "\n",
      "Documentation: @stevhliu\n",
      "\n",
      "HF projects:\n",
      "\n",
      "- accelerate: [different repo](https://github.com/huggingface/accelerate)\n",
      "- datasets: [different repo](https://github.com/huggingface/datasets)\n",
      "- diffusers: [different repo](https://github.com/huggingface/diffusers)\n",
      "- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\n",
      "\n",
      "Maintained examples (not research project or legacy):\n",
      "\n",
      "- Flax: @Rocketknight1\n",
      "- PyTorch: See Models above and tag the person corresponding to the modality of the example.\n",
      "- TensorFlow: @Rocketknight1\n",
      "\n",
      " -->\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = Github(g_token)  # 用你的 GitHub Token\n",
    "\n",
    "repo = g.get_repo(\"huggingface/transformers\")\n",
    "issues = repo.get_issues(state=\"closed\")  # 可加过滤条件\n",
    "# issues[0].__dict__\n",
    "# real_issues = [i for i in all_issues if not i.pull_request]\n",
    "for issue in issues[:2]:\n",
    "    print(\"Title:\", issue.title)\n",
    "    print(\"Body:\", issue.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "qa_pairs = []\n",
    "for issue in issues:\n",
    "    if issue.pull_request:\n",
    "        continue\n",
    "    # print(\"********************Issue********************\")\n",
    "    # print(\"Title:\", issue.title)\n",
    "    # print(\"Body:\", issue.body)\n",
    "    comments = issue.get_comments()\n",
    "    # print(\"********************Comments********************\")\n",
    "    comments_list = []\n",
    "    for comment in comments:\n",
    "        comments_list.append(\n",
    "            {\n",
    "                \"comment_author\": comment.user.login,\n",
    "                \"comment_body\": comment.body\n",
    "            }\n",
    "        )\n",
    "        # print(\"Comment by\", comment.user.login)\n",
    "        # print(comment.body)\n",
    "    qa_pair = {\n",
    "        \"Issue Title\": issue.title.strip(),\n",
    "        \"Issue Body\": issue.body.strip(),\n",
    "        \"Issue Comments\": comments_list,\n",
    "        \"source\": \"github_issue\",\n",
    "        \"metadata\": {\n",
    "            \"issue_number\": issue.number,\n",
    "            \"url\": issue.html_url,\n",
    "            \"created_at\": str(issue.created_at)\n",
    "        }\n",
    "    }\n",
    "    qa_pairs.append(qa_pair)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break\n",
    "\n",
    "\n",
    "with open(\"qa_from_issues.jsonl\", \"w\") as f:\n",
    "    for qa in qa_pairs:\n",
    "        f.write(json.dumps(qa, indent=4, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PR and Code Review Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PRS = 10  # 设定最多提取几个 PR，避免 API rate limit\n",
    "OUTPUT_FILE = \"huggingface_pr_data.jsonl\"\n",
    "\n",
    "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f_out:\n",
    "    for pr in repo.get_pulls(state=\"closed\", sort=\"created\", direction=\"desc\"):\n",
    "        if MAX_PRS <= 0:\n",
    "            break\n",
    "        MAX_PRS -= 1\n",
    "\n",
    "        pr_data = {\n",
    "            \"pr_number\": pr.number,\n",
    "            \"title\": pr.title,\n",
    "            \"body\": pr.body,\n",
    "            \"user\": pr.user.login,\n",
    "            \"created_at\": str(pr.created_at),\n",
    "            \"merged\": pr.merged,\n",
    "            \"merge_commit_sha\": pr.merge_commit_sha,\n",
    "            \"files\": [],\n",
    "            \"review_comments\": [],\n",
    "            \"general_comments\": [],\n",
    "        }\n",
    "\n",
    "        # PR 变更文件\n",
    "        try:\n",
    "            for file in pr.get_files():\n",
    "                pr_data[\"files\"].append({\n",
    "                    \"filename\": file.filename,\n",
    "                    \"status\": file.status,\n",
    "                    \"patch\": file.patch if hasattr(file, \"patch\") else None\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch files for PR #{pr.number}: {e}\")\n",
    "\n",
    "        # Code Review 评论\n",
    "        try:\n",
    "            for comment in pr.get_review_comments():\n",
    "                pr_data[\"review_comments\"].append({\n",
    "                    \"user\": comment.user.login,\n",
    "                    \"path\": comment.path,\n",
    "                    \"line\": comment.position,\n",
    "                    \"body\": comment.body\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch comments for PR #{pr.number}: {e}\")\n",
    "        \n",
    "        try:\n",
    "            issue = repo.get_issue(number=pr.number)\n",
    "            for comment in issue.get_comments():\n",
    "                pr_data[\"general_comments\"].append({\n",
    "                    \"user\": comment.user.login,\n",
    "                    \"created_at\": str(comment.created_at),\n",
    "                    \"body\": comment.body\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"[通用评论出错] PR #{pr.number}: {e}\")\n",
    "        # 保存为 JSONL 行\n",
    "        f_out.write(json.dumps(pr_data, indent=4, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 3856.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers\n",
      "Agents & Tools\n",
      "Agents\n",
      "Agent\n",
      "class transformers.Agent\n",
      "CodeAgent\n",
      "class transformers.CodeAgent\n",
      "React agents\n",
      "class transformers.ReactAgent\n",
      "class transformers.ReactJsonAgent\n",
      "class transformers.ReactCodeAgent\n",
      "ManagedAgent\n",
      "class transformers.ManagedAgent\n",
      "Tools\n",
      "load_tool\n",
      "tool\n",
      "Tool\n",
      "class transformers.Tool\n",
      "Toolbox\n",
      "class transformers.Toolbox\n",
      "PipelineTool\n",
      "class transformers.PipelineTool\n",
      "launch_gradio_demo\n",
      "stream_to_gradio\n",
      "ToolCollection\n",
      "class transformers.ToolCollection\n",
      "Engines\n",
      "TransformersEngine\n",
      "class transformers.TransformersEngine\n",
      "HfApiEngine\n",
      "class transformers.HfApiEngine\n",
      "Agent Types\n",
      "AgentText\n",
      "class transformers.agents.agent_types.AgentText\n",
      "AgentImage\n",
      "class transformers.agents.agent_types.AgentImage\n",
      "AgentAudio\n",
      "class transformers.agents.agent_types.AgentAudio\n",
      "✅ Done! Extracted 37 QA pairs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "\n",
    "def fetch_hf_doc(url):\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    return soup\n",
    "\n",
    "def extract_sections(soup):\n",
    "    qa_pairs = []\n",
    "    headers = soup.find_all(['h1', 'h2', 'h3'])\n",
    "\n",
    "    for header in tqdm(headers):\n",
    "        title = header.get_text().strip()\n",
    "        print(title)\n",
    "        content = []\n",
    "        next_sibling = header.find_next_sibling()\n",
    "\n",
    "        # Collect paragraphs and lists until the next header\n",
    "        while next_sibling and next_sibling.name not in ['h1', 'h2', 'h3']:\n",
    "            # if next_sibling.name in ['p', 'ul', 'ol', 'pre', 'li']:\n",
    "            content.append(next_sibling.get_text().strip())\n",
    "            next_sibling = next_sibling.find_next_sibling()\n",
    "\n",
    "        text = \"\\n\".join(content).strip()\n",
    "        if text:\n",
    "            qa_pairs.append(\n",
    "                {\n",
    "                    \"header\": title,\n",
    "                    \"content\": text,\n",
    "                    \"source\": \"huggingface_doc\",\n",
    "                    \"url\": soup.title.string if soup.title else \"N/A\"\n",
    "                }\n",
    "            )\n",
    "            # question, answer = make_qa_from_section(title, text)\n",
    "\n",
    "            # if question:\n",
    "            #     qa_pairs.append({\n",
    "            #         \"question\": question,\n",
    "            #         \"answer\": answer,\n",
    "            #         \"source\": \"huggingface_doc\",\n",
    "            #         \"metadata\": {\n",
    "            #             \"section_title\": title,\n",
    "            #             \"url\": soup.title.string if soup.title else \"N/A\"\n",
    "            #         }\n",
    "            #     })\n",
    "\n",
    "    return qa_pairs\n",
    "\n",
    "def make_qa_from_section(title, text):\n",
    "    \"\"\"\n",
    "    基于标题和内容生成问题模板\n",
    "    \"\"\"\n",
    "    if len(text.split()) < 5:\n",
    "        return None, None\n",
    "\n",
    "    # 简单模板化问题构造\n",
    "    if \"tokenizer\" in title.lower():\n",
    "        q = f\"What is {title} in HuggingFace Transformers?\"\n",
    "    elif title.lower().startswith(\"how\"):\n",
    "        q = title + \"?\"\n",
    "    elif \"parameters\" in title.lower():\n",
    "        q = f\"What parameters does {title} include?\"\n",
    "    else:\n",
    "        q = f\"What does '{title}' refer to in Transformers?\"\n",
    "\n",
    "    return q, text\n",
    "\n",
    "def save_to_jsonl(data, filename=\"hf_qa_output.jsonl\"):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item, indent=4, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "url = \"https://huggingface.co/docs/transformers/en/main_classes/agent#transformers.Agent\"  # 你可以替换成其他页面\n",
    "soup = fetch_hf_doc(url)\n",
    "qa_pairs = extract_sections(soup)\n",
    "save_to_jsonl(qa_pairs)\n",
    "print(f\"✅ Done! Extracted {len(qa_pairs)} QA pairs.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformerQA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
